---
title: "Scraping Text"
description: |
  Marketing Analytics
author:
  - name: Berry-Cherian Experience 
output:
  radix::radix_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Last time, we played around with scraping tables:

```{r}
library(rvest)

library(magrittr)

cpiTable = read_html("https://www.usinflationcalculator.com/inflation/consumer-price-index-and-annual-percent-changes-from-1913-to-2008/") %>% 
  html_table() %>% 
  magrittr::extract2(1) # or `[[`(1) 
```

As helpful as getting tables might be, there will be other bits of data that we might want to be able to pull. For example, we might want to keep track of who is sitting on a <a href="https://www.apple.com/leadership/">Board of Directors</a>. That is clearly not a table, so how do we get at it?

After inspecting the elements of the names and roles, we should have a pretty good idea about the *nodes* that we are trying to pull.

```{r}
appleBoard = data.frame(name = read_html("https://www.apple.com/leadership/") %>% 
                          html_nodes(".typography-body.block-link.profile-name") %>% 
                          html_text(), 
                        role = read_html("https://www.apple.com/leadership/") %>% 
                          html_nodes(".typography-body.typography-profile-title") %>% 
                          html_text(), 
                        stringsAsFactors = FALSE)

knitr::kable(appleBoard)
```

That is a pretty simple example of finding some text and pulling it in as data.

## Packages

The following packages will be extremely useful to us:

```{r}
library(dplyr)

library(ggplot2)

library(magrittr) # maybe

library(rvest)

library(stringr)
```


## Scraping Text

Yelp will be a good place to start scraping some data, and for a few reasons: it is well structured, there is a nice chunk of data to be gotten, and it is rich with text. Furthermore, it will be a good starting point for our sentiment analysis next time.

### Evil Czech

```{r}
evilCzech = "https://www.yelp.com/biz/evil-czech-brewery-and-public-house-mishawaka"

evilCzechHTML = read_html(evilCzech) # This pulls the entire html tree

ecRatings = evilCzechHTML %>% 
  html_nodes(".review-wrapper .review-content .i-stars") %>% # Grabbing specific nodes
  html_attr("title") %>% # Getting the title attribute from the nodes
  stringr::str_extract("[0-5]") # Just keeping the number within the rating

ecReviews = evilCzechHTML %>% 
  html_nodes(".review-wrapper .review-content p") %>% 
  html_text()

evilCzechData = data.frame(ratings = ecRatings, 
                           reviews = ecReviews,
                           restaurant = "evil czech", 
                           stringsAsFactors = FALSE)
```


### Fiddler's Hearth

```{r}
fiddlers = "https://www.yelp.com/biz/fiddlers-hearth-south-bend"

fiddlersHTML = read_html(fiddlers)

fhRatings = fiddlersHTML %>% 
  html_nodes(".review-wrapper .review-content .i-stars") %>% 
  html_attr("title") %>% 
  stringr::str_extract("[0-5]")

fhReviews = fiddlersHTML %>% 
  html_nodes(".review-wrapper .review-content p") %>% 
  html_text()

fhData = data.frame(ratings = fhRatings, 
                    reviews = fhReviews, 
                    restaurant = "fiddlers hearth", 
                    stringsAsFactors = FALSE)
```


### Crooked Ewe

```{r}
crookedEwe = "https://www.yelp.com/biz/crooked-ewe-brewery-and-ale-house-south-bend"

crookedEweHTML = read_html(crookedEwe)

ceRatings = crookedEweHTML %>% 
  html_nodes(".review-wrapper .review-content .i-stars") %>% 
  html_attr("title") %>% 
  stringr::str_extract("[0-5]")

ceReviews = crookedEweHTML %>% 
  html_nodes(".review-wrapper .review-content p") %>% 
  html_text()

ceData = data.frame(ratings = ceRatings, 
                    reviews = ceReviews, 
                    restaurant = "crooked ewe", 
                    stringsAsFactors = FALSE)
```


### Cambodian Thai

```{r}
cambodianThai = "https://www.yelp.com/biz/cambodian-thai-south-bend"

cambodianThaiHTML = read_html(cambodianThai)

ctRatings = cambodianThaiHTML %>% 
  html_nodes(".review-wrapper .review-content .i-stars") %>% 
  html_attr("title") %>% 
  stringr::str_extract("[0-5]")

ctReviews = cambodianThaiHTML %>% 
  html_nodes(".review-wrapper .review-content p") %>% 
  html_text()

ctData = data.frame(ratings = ctRatings, 
                    reviews = ctReviews, 
                    restaurant = "cambodian thai", 
                    stringsAsFactors = FALSE)
```

### Corndance Tavern

```{r}
corndance = "https://www.yelp.com/biz/corndance-tavern-mishawaka"

corndanceHTML = read_html(corndance)

cdRatings = corndanceHTML %>% 
  html_nodes(".review-wrapper .review-content .i-stars") %>% 
  html_attr("title") %>% 
  stringr::str_extract("[0-5]")

cdReviews = corndanceHTML %>% 
  html_nodes(".review-wrapper .review-content p") %>% 
  html_text()

cdData = data.frame(ratings = cdRatings, 
                    reviews = cdReviews, 
                    restaurant = "corndance tavern", 
                    stringsAsFactors = FALSE)
```


At the end, we did a lot of copy and paste action there. Once you are down your R path a little bit more, you might find yourself writing functions to handle the heavy lifting and minimizing your copy and paste time. 

### Combining Data

After running all of the previous code, we have 5 distinct data frames. We need to combine them into one:

```{r}
allReviews = dplyr::bind_rows(cdData, ceData, ctData, evilCzechData, fhData)
```

Now would be a really good place to make note about the different variable types that you might encounter when scraping data (and data types in R generally). 

If we try to do something reasonable like taking the mean rating, we might see some issue:

```{r, eval = FALSE}
mean(allReviews$ratings)
```

Why did this happen? Looking at the data structure will help us:

```{r}
str(allReviews)
```

Our rating variable really is not a number -- it is a character.

Let's change our ratings to numbers and try something a little bit different (we will count the number of words in each review). We will use the `mutate` function to add new variables to our data:

```{r}
allReviews = allReviews %>% 
  dplyr::mutate(ratings = as.numeric(ratings), 
                wordCount = stringr::str_count(reviews, pattern = "\\S+"))
```

Let's try to get our mean again:

```{r}
mean(allReviews$ratings)
```

You should try to get the mean for number of words!

When scraping data, you always need to consider what the data looks like when you get it in. For the sake of demonstration, let's go back to an individual restaurant:

```{r}
ecStars = evilCzechHTML %>% 
  html_nodes(".review-wrapper .review-content .i-stars") %>% 
  html_attr("title")

ecStars
```

We see that we would likely need to do a little cleaning on these values. We already saw one way to do it with `str_extract()`, but here is a slightly different way:

```{r}
stringr::str_replace_all(ecStars, pattern = " star rating", replacement = "")
```
This is particularly useful when a table (or text) has dollar signs!

Now, we can check on some visuals from our data:

```{r}
ggplot(allReviews, aes(x = ratings, y = wordCount, group = ratings)) + 
  geom_boxplot() + 
  theme_minimal()
```

This is slightly following an inverted U (tenuously, at best), which I would expect. Let's not forget that we have a natural grouping variable in restaurant. There are countless ways to look at this in R:

Here are boxplots broken out into small multiples by restaurant:

```{r}
ggplot(allReviews, aes(ratings, wordCount, group = ratings)) + 
  geom_boxplot() + 
  facet_wrap(~ restaurant) + 
  theme_minimal()
```

Or we can scrap the boxplot and use scatterplots:

```{r}
library(gganimate)

ggplot(allReviews, aes(ratings, wordCount, color = restaurant)) + 
  geom_point(alpha = .5) + 
  scale_color_brewer(type = "qual", palette = "Dark2") +
  theme_minimal()
```

And with just a little more effort, we can animate that plot:

```{r}
library(gganimate)

ggplot(allReviews, aes(ratings, wordCount)) + 
  geom_point(aes(group = restaurant, color = restaurant), size = 3) + 
  scale_color_brewer(type = "qual", palette = "Dark2") +
  transition_states(restaurant, transition_length = 5, state_length = 2) + 
  enter_fade() + 
  exit_shrink() +
  theme_minimal()
```

We could also turn it into a fully interactive visualization:

```{r}
library(plotly)

scatterTest = ggplot(allReviews, aes(ratings, wordCount)) + 
  geom_point(aes(group = restaurant, color = restaurant), size = 3) + 
  scale_color_brewer(type = "qual", palette = "Dark2") +
  theme_minimal()

ggplotly(scatterTest)
```

Finally, we might want to play with a model:

```{r}
ratingsMod = lm(ratings ~ wordCount, data = allReviews)

summary(ratingsMod)
```

Remember when we counted the words within a review? You should try to do that with exclamation marks and see what that looks like in a model!

This is just a brief dip into scraping text from the web. It is something that takes a fair amount of practice for doing it in a "production" manner, but you can quickly grab some interesting stuff without too much hassle.