---
title: "General Linear Model"
description: |
  Expanded Topics
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We have already seen the basics of the general linear model (linear regression, *t*-tests, and ANOVAs). Now, we are going to get into some expanded topics related to the general linear model: centering, interactions, two-way ANOVAs, and statistical power.

## Centering

Think back to what the intercept means in the context of a linear regression model: it is the value of the DV/outcome when everything else is at 0. There are times where that makes sense (you can have 0 dollars, but I don't recommend it). 

What if we want to have a meaningful intercept?

```{r}
crimeScore = data.table::fread("http://nd.edu/~sberry5/data/crimeScore.csv")

library(dplyr)

uncentered = lm(SSL_SCORE ~ NARCOTICS_ARR_CNT, data = crimeScore)

summary(uncentered)

plot(uncentered$fitted.values, uncentered$model$SSL_SCORE)

plot(uncentered$model$SSL_SCORE, uncentered$model$NARCOTICS_ARR_CNT)
```

Now we can do some very simple centering: we can just subtract the mean of the item from every observation of that item.

```{r}
centeredMod <- crimeScore %>% 
  mutate(narcCenter = NARCOTICS_ARR_CNT - mean(NARCOTICS_ARR_CNT, na.rm = TRUE)) %>% 
  lm(SSL_SCORE ~ narcCenter, data = .)

summary(centeredMod)

plot(centeredMod$fitted.values, centeredMod$model$SSL_SCORE)

plot(centeredMod$model$SSL_SCORE, centeredMod$model$narcCenter)
```

We can see that nothing really changes except for the intercept's coefficient. Let's think about what is being said here: with narcotics arrest count being a 0, we would expect the SSL score to be 277 on average. Since we centered that narcotics variable, though, the 0 is actually the mean of that variable (2.06). 

## Interactions

We will get back to more interesting data in a second, but let's look at some mtcars data first (we can't possibly learn anything new about it):

```{r}
library(ggplot2)

ggplot(mtcars, aes(mpg, hp)) + 
  geom_point() +
  geom_smooth(method = "lm")
```

We can clearly see the effect of horsepower on mpg.

Let's add some additional context to this visualization:

```{r}
ggplot(mtcars, aes(mpg, hp, color = as.factor(cyl))) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

We have already been doing stuff like this, but not really thinking about the model that could test it.


Let's start by looking at a multiple regression with 2 predictor variables:

```{r}
twoVars = lm(SSL_SCORE ~ WEAPONS_ARR_CNT + NARCOTICS_ARR_CNT, data = crimeScore)

summary(twoVars)
```

Let's explore interactions (moderation to some). A key idea here is that interactions change the nature of our model. Instead of supposing that the predictor variables act in isolation on the DV, the interaction is essentially providing expanded context for our model. We are essentially saying that the values of one variable will have an effect with values of another variable on the DV. Here is what this looks like in words:

"What is the effect of X on Y?"

"It depends on Z's value."


<aside>
A thing called *mediation* also exists, but it tests a slightly different model.
</aside>

```{r}
intMod = lm(SSL_SCORE ~ WEAPONS_ARR_CNT * NARCOTICS_ARR_CNT, data = crimeScore)

summary(intMod)
```

This is the model that we have estimated:

$$score = b_0 + b_1(weapons) + b_2(narcotics) + b_3(weapons*narcotics)$$

The interpretation of our main effects don't really change. 

Our interaction terms ($b_3$) is providing the amount of change in the slope of the regression of score on weapons when narcotics changes by one unit. So as narcotics arrests increase, we see an increase in the effect of weapons arrests on score (but only a tiny one).

To predict what the score value would be for certain values of weapons arrests, we could reformulate our model as:

$$score = b_0 + (b_1 + b3*narcotics)weapons + b_2(narcotics)$$



```{r}
library(effects)

modEffects = effect("WEAPONS_ARR_CNT*NARCOTICS_ARR_CNT", intMod)

plot(modEffects)
```

This is offering the relationship between weapons arrests and score at various levels of narcotics arrests.

```{r}
crimeScoreGender = crimeScore %>% 
  filter(SEX_CODE_CD != "X") %>%
  dplyr::select(SSL_SCORE, SEX_CODE_CD, WEAPONS_ARR_CNT) %>% 
  mutate(SEX_CODE_CD = as.factor(SEX_CODE_CD))

intMod2 = lm(SSL_SCORE ~ WEAPONS_ARR_CNT * SEX_CODE_CD, data = crimeScoreGender)

summary(intMod2)
```

Compared to women, men's score increases by 19.25 on average for each weapons arrest.

Sometimes it helps to see what is going on with a plot:

```{r}
modEffects = effect("WEAPONS_ARR_CNT*SEX_CODE_CD", intMod2)

plot(modEffects)
```

Here is another way (and probably easier) to visualize this effect:

```{r}
library(interactions)

interact_plot(intMod2, pred = WEAPONS_ARR_CNT, modx = SEX_CODE_CD)
```


```{r}
sim_slopes(intMod2, pred = WEAPONS_ARR_CNT, modx = SEX_CODE_CD)
```

For the sake of it, let's look at one more continuous by continuous interaction:


```{r}
domNarc = lm(SSL_SCORE ~ NARCOTICS_ARR_CNT * DOMESTIC_ARR_CNT , data = crimeScore)

summary(domNarc)
```

Let's look at these interactions:

```{r}
probe_interaction(domNarc, pred = NARCOTICS_ARR_CNT, modx = DOMESTIC_ARR_CNT)
```

And also some categorical interactions:

```{r}
crimeScore2 = crimeScore %>% 
  filter(AGE_CURR != "" & SEX_CODE_CD != "X") %>% 
  mutate(AGE_CURR = relevel(as.factor(.$AGE_CURR), ref = "less than 20"))

sexMod = lm(SSL_SCORE ~ SEX_CODE_CD, data = crimeScore2)

summary(sexMod)

ageMod = lm(SSL_SCORE ~ AGE_CURR, data = crimeScore2)

summary(ageMod)

sexAge = lm(SSL_SCORE ~ SEX_CODE_CD * AGE_CURR, data = crimeScore2)

summary(sexAge)
```

```{r}
cat_plot(sexAge, pred = SEX_CODE_CD, modx = AGE_CURR, geom = "line")
```


## Two-way ANOVA

Remember that whole issue with the ANOVA being the flipped regression, we can highlight that perfectly here:

```{r}
summary(aov(SSL_SCORE ~ SEX_CODE_CD + AGE_CURR, data = crimeScore2))

summary(aov(SSL_SCORE ~ SEX_CODE_CD * AGE_CURR, data = crimeScore2))
```

```{r}
TukeyHSD(aov(SSL_SCORE ~ SEX_CODE_CD + AGE_CURR, data = crimeScore2), which = "SEX_CODE_CD:AGE_CURR")
```

# Effect Sizes

Effect sizes, in conjunction with our *p*-values, will provide a really good idea about the strength of the difference.

With regard to effect sizes, you will most commonly come across Cohen's *d* -- it is generally used for *t*-tests.

Computationally, it is pretty simple:

$$ \frac{\mu_1 - \mu_2}{\sigma}$$

There is also an expanded version:

$$ d = \frac{\mu_1-\mu_2}{\sigma_{pooled}} $$

$$ SD_{pooled} = \sqrt{\frac{\sigma_1^2 + \sigma_2^2}{2}} $$


We are subtracting the mean of one group from another and dividing by the standard deviation.

```{r}
library(dplyr)

crimeScoreGender %>%
  group_by(SEX_CODE_CD) %>%
  summarize(mean = mean(SSL_SCORE),
            sd = sd(SSL_SCORE),
            n = n())

sd(crimeScoreGender$SSL_SCORE)
```


We can do it by hand:

```{r}
(283.46-278.689) / 57.99564
```

And with the pooled method:

```{r}
sdPooled = sqrt((52.74889^2 + 59.52397^2) / 2)

(283.46-278.689) / sdPooled
```


Or use things already built:

```{r}
library(compute.es)

tes(t = 23.674, n.1 = 96307, n.2 = 302320)

mes(m.1 = 283.46, m.2 = 278.689,
    sd.1 = 52.74889, sd.2 = 59.52397,
    n.1 = 96307, n.2 = 302320)
```

# Power Analysis

Rules of thumb have been around for a long time and have changed over the years -- maybe you learned that you needed 20 rows per predictor, or maybe even 50 rows per predictor. Instead of trusting outdated advice, use actual science to determine how many people you need to find if a difference exists.

We need three of the following parameters:

-  Effect size

-  Sample size

-  Significance level

-  Power

We **should** always be doing this *a priori*.

## Power

Power is ability to detect an effect. In NHST words, we are trying to determine if we correctly reject the null hypothesis.

- Type I errors: Reject a true $H_{o}$ (false positive -- saying something is there when it is not)

- Type II errors: Reject a false $H_{o}$ (false negative -- saying something is not there when it is)

## Putting It All Together

Let's use the <span class="func">pwr</span> package.

```{r}
library(pwr)

pwr.f2.test(u = 1, v = NULL, f2 = .05, power = .8)
```

In the function:

- u is the numerator df (*k* - 1)

- v is the denominator df (*n* - *k*)

- f2 is signficance level

- \(\Pi = 1 -\beta\)

- \(\beta = Type\,II_{prob}\)

Power is typically set at .8, because it represents a 4 to 1 trade between Type II and Type I errors.


## Different Test, Different Power Tests

We just did a test for a linear regression model.

Here is one for a *t*-test:

```{r}
tPower = pwr.t.test(n = NULL, d = 0.1, power = 0.8,
                    type = "two.sample", alternative = "greater")

plot(tPower)
```




Let theory be your guide (but be realistic).

## Power

Power is ability to detect an effect.

- In NHST words, we are trying to determine if we correctly reject the null hypothesis.

- Type I errors: Reject a true $H_{o}$ (false positive)

- Type II errors: Reject a false $H_{o}$ (false negative)

We typically set power to be .8 or .9 (depending upon the context). Th

## Putting It All Together

Let's use the `pwr` package.

Here is how we can determine a necessary sample size for a regression. We just need the numerator and denominator degrees of freedom for the *F*-test.

We also need to specify the size of our effect. Here is an estimate for a medium effect size:


```{r}
library(pwr)

pwr::cohen.ES("f2", "medium")
```

We can pop that into the `pwr.f2.test` function:

```{r}
pwr.f2.test(u = 1, v = NULL, f2 = .15, power = .8)
```

In the function: 

- u is the numerator df (*k* - 1)

- v is the denominator df (*n* - *k*) 

- f2 is the effect size


## Your Turn!

Use various values to do an *a priori* power analyses.

How does the proposed sample size change as the number of predictors goes up?

What if you tweak the significance level?

What about power?


## Different Test, Different Power Tests

We just did a test for a linear regression model.

Here is one for a *t*-test:

```{r}
tPower = pwr.t.test(n = NULL, d = 0.1, power = 0.8, 
                    type= "two.sample", alternative = "greater")

plot(tPower)
```

  