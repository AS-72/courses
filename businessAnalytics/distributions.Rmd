---
title: "Distributions"
output: distill::distill_article
---

```{r setup, include=FALSE, echo = FALSE, warning=FALSE, message = FALSE, comment = ""}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, comment = "")
```

### The Normal Distribution

The normal distribution should not be too much of a mystery to us.

```{r}
library(ggplot2)

library(gridExtra)

set.seed(123)

r = 10000

n = 200     

population = data.frame(population = rnorm(n = 1000000, mean = 0, sd = 1))

sample.means = function(samps, r, n) {
  rowMeans(matrix(samps, nrow = r, ncol = n))
}

qqplot.data = function(vec) {
  y = quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x = qnorm(c(0.25, 0.75))
  slope = diff(y) / diff(x)
  int = y[1L] - slope * x[1L]

  d = data.frame(resids = vec)
  
  return(d)
}

generate.plots = function(samps, samp.means) {
  p1 = qplot(samps, geom = "histogram", bins = 30, 
             main = "Sample Histogram") + 
    theme_minimal()
  p2 = qplot(samp.means, geom = "histogram", bins = 30, 
             main="Sample Mean Histogram") + 
    theme_minimal()
  grid.arrange(p1,p2,ncol=2)
}

regions = data.frame(sdPlus1 = mean(population$population) + sd(population$population), 
                     sdMinus1 = mean(population$population) - sd(population$population), 
                     sdPlus2 = mean(population$population) + (2 * sd(population$population)), 
                     sdMinus2 = mean(population$population) - (2 * sd(population$population)), 
                     sdPlus3 = mean(population$population) + (3 * sd(population$population)), 
                     sdMinus3 = mean(population$population) - (3 * sd(population$population)))

ggplot(population, aes(population)) +
  geom_density() +
  theme_minimal()
```


If we are observing a population that is normally distributed, we can know some things about it: the mean and the standard deviation. We also know that the mean, median, and mode are all the same. 

There is also a convenient rule: the 68-95-99.7 rule. This rule dictates that 68% of the distribution is contained within $\pm1\sigma$, 95% is contained within $\pm2\sigma$, and 99.7% is contained within $\pm3\sigma$. It is not functionally part of the rule, but 99.99% is contained under $\pm4\sigma$.

```{r}
ggplot(population, aes(population)) +
  geom_density() +
  geom_vline(xintercept = regions$sdPlus1, color = "red") +
  geom_vline(xintercept = regions$sdMinus1, color = "red") +
  geom_vline(xintercept = regions$sdPlus2, color = "blue") +
  geom_vline(xintercept = regions$sdMinus2, color = "blue") +
  geom_vline(xintercept = regions$sdPlus3, color = "green") +
  geom_vline(xintercept = regions$sdMinus3, color = "green") +
  theme_minimal()
```


The normal distribution is important, as many things are naturally normally distributed.

### Galton Boards

```{r, eval = FALSE}
library(animation)

ani.options(nmax = 215, interval = .5, autoplay = FALSE)

quincunx()
```


## Uniform Distribution

Likely the most vanilla of all distributions, the uniform distribution is pretty simple. We don't even get any fancy Greek letters to give us an idea about its shape, just a minimum and a maximum. Why? Because knowing the min and max will tell us that there is an equal probability of drawing a value anywhere within that range.

```{r}
samps = runif(r * n)

samp.means = sample.means(samps, r, n)

generate.plots(samps, samp.means)
```


### Poisson

The Poisson is an interesting distribution -- it tends to deal with count-related variables. It tells us the probability of a count occurring.  We know its $\lambda$, or average number of events (incidence rate).

```{r}
samps = rpois(r * n, lambda = 3)

samp.means = sample.means(samps, r, n)

generate.plots(samps, samp.means)
```


### Exponential

The exponential distribution is excellent when we are looking at how long something lasts or arrivals within a process (car part life, people joining a line, survival). We can only know one thing about the exponential distribution: $\mu$

```{r}
samps = rexp(r * n, rate = 1)

samp.means = sample.means(samps, r, n)

generate.plots(samps, samp.means)
```

## Determining Distributions

There might be times when you want to see how a variable might be distributed:

```{r, echo = TRUE}

library(fitdistrplus)

normalTest = rnorm(1000, mean = 2.5, sd = 1)

descdist(normalTest)

plot(fitdist(normalTest, distr = "norm"))

```

Of course we were able to fit a normal distribution to our data -- we created it by drawing from a normal distribution! Determining the underlying distribution of a variable has implications when we start using variables in models. 


## Populations and Samples

### Central Limit Theorem

The CLT dictates that as we increase the number of samples from a population, we will begin to approach normally-distributed means.

```{r}
pos = replicate(1000, sum(runif(16, -1, 1)))

plot(density(pos))
```


```{r}
library(plyr)

dataSteps = function(stepSize) {
  walks = data.frame(person = rep(1:100, each = stepSize), 
           position = unlist(rlply(100, cumsum(c(0, runif((stepSize - 1), -1, 1))))), 
           step = rep(1:stepSize, times = 100))
  
  return(walks)
}

walks = dataSteps(16)

ggplot(walks, aes(step, position, group = person)) + 
  geom_line(color = "#ff5500", alpha = .5) + 
  theme_minimal()
```



### Sampling From Distributions

Let's start with a Gaussian distribution of 10000 observations:

```{r, echo = TRUE}
set.seed(1001)

population = rnorm(10000)

plot(density(population))
```

Now, let's take a small sample (*n* = 75) of our population:

```{r, echo = TRUE}
set.seed(1001)

smallSample = sample(population, 75, replace = FALSE)

plot(density(smallSample))
```

And now something a little bigger (*n* = 250):

```{r, echo = TRUE}
set.seed(1001)

mediumSample = sample(population, 250, replace = FALSE)

plot(density(mediumSample))
```

And bigger still (*n* = 1000):

```{r, echo = TRUE}
set.seed(1001)

biggerSample = sample(population, 1000, replace = FALSE)

plot(density(biggerSample))
```


And finally *n* = 2500:

```{r, echo = TRUE}
set.seed(1001)

biggestSample = sample(population, 2500, replace = FALSE)

plot(density(biggestSample))
```

Original:

```{r}
plot(density(population))
```


### What Is The Point?

We had our "population", so how well did our samples replicate the population distribution?

This starts to illustrate the *t*-distribution (more on this in a few weeks).

We are also getting into issues related to point estimation.

Let's consider the following:

```{r, echo = TRUE}
mean(population)

mean(biggerSample)

mean(biggestSample)
```

We can even take another sample from our population:

```{r, echo = TRUE}
mean(sample(population, 2500, replace = FALSE))
```

Let's take a bigger sample:

```{r, echo = TRUE}
mean(sample(population, 5000, replace = FALSE))
```

In and of itself, this is interesting. It has applications, however, to null hypothesis significance testing.