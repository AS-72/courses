---
title: "Optical Character Recognition"
description: |
  Theory and Practice
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Packages

```{r, eval = FALSE}
install.packages(c("kernlab", "magick", "tesseract", "pdftools"))
```

Give the following a try, but move on if it does not work!

```{r, eval = FALSE}
install.packages(c("rJava", "tabulizer"))
```

If it does not work, look at this <a href="https://github.com/ropensci/tabulizer">github</a> page when on your own machine.

# Text

So far, we have been in the world of text made with the sole intention of displaying it on a screen. That is, however, just a very small slice of the text that is out in the world. Take a pdf file, for instance. We would imagine that it has been generated for appearing on a screen, but it is a vastly different animal than our traditional web-based print. 

# Support Vector Machines

Just like our old friends decision trees and random forest, <a href="http://web.mit.edu/6.034/wwwbob/svm.pdf">SVM</a> is a technique that can prove to be useful for both regression and classification. In the context of text, we will use SVM's classification abiliities. One really great thing about a standard SVM is that it will likely outperform a standard neural network for most tasks.

## Conceptual Background

SVM is popular because it is both powerful and conceptually easy to understand. Since we are dealing with a classifier at heart, all we are doing is defining a hyperplane that will separate data in (hyper)dimensional space. Easy, right?

Let's look at the following plot with 2 classes:

```{r, echo = FALSE}
library(ggplot2)

set.seed(1002)

plotDat = data.frame(x = c(rnorm(10, mean = 2), rnorm(10, mean = 5)), 
                     y = c(rnorm(10, mean = 8), rnorm(10, mean = 3)), 
                     class = as.factor(c(rep(0, 10), rep(1, 10))))

pointPlot = ggplot(plotDat, aes(x, y, color = class)) + 
  geom_point() +
  theme_minimal()

pointPlot

```

Now we can get to those hyperplanes. We need to define that margin so that it does a few things:

1.  It needs to separate the points properly based upon the classifications.

2.  It needs to maximize the amount of distance between itself and the groups (this is called the margin).


Let's look at some candidate lines:

```{r}
pointPlot + 
  geom_abline(intercept = 0, color = "red") +
  geom_abline(intercept = 1, color = "blue") + 
  geom_abline(intercept = 2, color = "green") +
  geom_abline(intercept = 3, color = "black")
```

So to fulfill our first condition, we can immediately rule out the red line. We now have three lines that might work:

```{r}
pointPlot + 
  geom_abline(intercept = 1, color = "blue") + 
  geom_abline(intercept = 2, color = "green") +
  geom_abline(intercept = 3, color = "black")
```

With the remaining lines, which one maximizes the margin between the classes? 

```{r}
pointPlot + 
  geom_abline(intercept = 2, color = "green")
```

That looks like an appropriate hyperplane, but what are the support vectors? They are the individual vectors (observations) that help to define the hyperplane!


## Attrition (again)

R has many classic packages, with `e1071` being one of them. For our work in caret, will play with `kernlab`.

```{r}
library(caret)

library(dplyr)

library(kernlab)

library(rsample)

attrition = attrition %>%
  mutate_at(c("JobLevel", "StockOptionLevel", "TrainingTimesLastYear"), factor)

set.seed(1001)

split = initial_split(attrition, prop = .6, strata = "Attrition")

attritionTrain = training(split)

attritionTest  = testing(split)

svmTrainControl = trainControl(method = "cv", number = 10, verboseIter = FALSE)

nbAttrition = train(Attrition ~ ., data = attritionTrain,
  method = "svmLinear", trControl = svmTrainControl, metric = "Accuracy")

nbAttrition
```

We see that we have a tuning parameter called `C` (Cost). Remember the planes that we drew earlier, where the goal was to correctly classify and maximize the margins? We cannot always do both in reality and the `C` parameter indicates which we prefer. Higher C values will push us towards *c*orrect classification over maximizing the margins. It essentially serves as a regularization parameter. The values that the `C` parameter can be very small (think .000001) to very large (1000). 

```{r}
svmAttrition = train(Attrition ~ ., data = attritionTrain,
  method = "svmLinear", trControl = svmTrainControl, 
  tuneGrid = data.frame(C = c(.001, .1, .5, 1, 5, 10, 100)), 
  metric = "Accuracy", preProc = c("center", "scale"))
```

A `C` parameter of .1 tends to get us the best accuracy, but they are all pretty close to each other.

```{r}
svmAttritionTuned = train(Attrition ~ ., data = attritionTrain,
  method = "svmLinear", trControl = svmTrainControl, 
  tuneGrid = data.frame(C = .1), 
  metric = "Accuracy", preProc = c("center", "scale"))

confusionMatrix(svmAttritionTuned)
```

Now, we can test our model:

```{r}
svmAttritionTest = predict(svmAttritionTuned, attritionTest)

confusionMatrix(svmAttritionTest, attritionTest$Attrition)
```

I think it is fair to say that this model performed better than our simple neural network and our Naive Bayes. 

What about the lyrics?

```{r}
if(Sys.info()["sysname"] == "Darwin") {
  load("~/courses/unstructured/data/textFeatures.RData")
} else load("C:/Users/sberry5/Documents/teaching/courses/unstructured/data/textFeatures.RData")

textFeatures$genre = ifelse(textFeatures$genre == "zappa", 1, 0)

textFeatures$genre = as.factor(make.names(textFeatures$genre))

set.seed(1001)

trainRows <- rsample::initial_split(textFeatures, prop = .7, strata = "genre")

testingData = rsample::testing(trainRows)

trainingData = rsample::training(trainRows)

svmGenreTuned = train(genre ~ ., data = trainingData,
  method = "svmLinear", trControl = svmTrainControl, 
  tuneGrid = data.frame(C = c(.001, .1, .5, 1, 5, 10, 100)), 
  metric = "Accuracy", preProc = c("center", "scale"))

svmGenreTest = predict(svmGenreTuned, testingData)

confusionMatrix(svmGenreTest, testingData$genre)
```

Nothing happening there...

Instead of looking at text as a collection of words that might have some meaning, we are going to look at the shape of text -- in other words, the letters. Why might we do this? For starters, we can think again about an aforementioned PDF or other written text.

## Letter Data

```{r}
library(rvest)

letterData = readr::read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data", 
                             col_names = FALSE)

letterName = read_html("https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.names") %>% 
  html_text() %>% 
  stringr::str_replace_all(., "\t", " ") %>%
  readr::read_lines() %>% 
  stringr::str_extract(., "(?<=^\\s[0-9]{1,2}\\.\\s)\\w+-*\\w*|(?<=^\\s\\s[0-9]{1,2}\\.\\s)\\w+-*\\w*") %>% 
  na.omit()

names(letterData) = letterName

rmarkdown::paged_table(letterData)
```

This is classic letter data, in which the shape of letters has been broken down to 16 features. 

We can go through our now routine data-prep steps:

```{r}
splitLetter = initial_split(letterData, prop = .8, strata = "lettr")

letterTrain = training(splitLetter)

letterTest  = testing(splitLetter)

svmTrainControl = trainControl(method = "cv", number = 10, verboseIter = FALSE)

svmLetterLinear = train(lettr ~ ., data = letterTrain, method = "svmLinear", 
                        trControl = svmTrainControl, metric = "Accuracy", 
                        preProcess = c("center", "scale"), 
                        tuneGrid = data.frame(C = c(.0001, .001, 1, 10, 100)))

svmLetterLinear

svmLetterTest = predict(svmLetterLinear, letterTest)

confusionMatrix(svmLetterLinear, letterTest$lttr)

prop.table(table(svmLetterTest == letterTest$lettr))
```

This exercise leads us to a really interesting point about our SVM models -- the mapping of the support vectors. As they have been, we are trying to map our lines in linear (multidimensional) space. 

```{r}
library(plotly)

plot_ly(letterData, x = ~`x-box`, y = ~`y-box`, z = ~onpix, color = ~lettr, 
          type= "scatter3d", mode = "markers")
```

That is going to be a nope for me. We are dealing with only 3 dimensions (out of several more) and I am not entirely convinced that we could find linear lines to do that splitting for us (eyes cannot, but a machine might be able to).

Instead, we can do some kernel transformations for the SVD -- this is often referred to as the *kernel trick*. This kernel transformation can take our non-separable linear space, transform it to even higher dimensional space, and then achieve linear separation. It does this in a way that is computationally easier than engaging in higher dimensional dot products just to achieve a single value. This improved separation in data might lead to better predictions. The particular type of kernel we will use for our SVM is a <a href="https://num.math.uni-goettingen.de/schaback/teaching/sc.pdf">radial basis function</a>.

We will also add in a new tuning parameter: sigma. Sigma is going to control the smoothness of the decision boundary. Since we are dealing in nonlinear space, the decision boundary can be very choppy (low values of sigma and likely to overfit -- essentially a local classifier) or very smooth (higher values of sigma and more likely to produce training errors -- a global classifier).

```{r, eval = FALSE}
tuningGrid = expand.grid(C = c(1, 5, 10), 
                         sigma = c(.5, 1, 5, 10))

svmLetterRBF = train(lettr ~ ., data = letterTrain, method = "svmRadial", 
                        trControl = svmTrainControl, metric = "Accuracy", 
                        preProcess = c("center", "scale"), 
                        tuneGrid = tuningGrid)
```

```{r}
load("C://Users/sberry5/Documents/teaching/courses/unstructured/data/svmLetterRBF.RData")

svmLetterRBF
```

It appears that a higher Cost, coupled with a lower sigma, leads to the best prediction

```{r}
svmLetterRBFTest = predict(svmLetterRBF, letterTest)

confusionMatrix(svmLetterRBFTest, as.factor(letterTest$lettr))

prop.table(table(svmLetterRBFTest == letterTest$lettr))
```

I would say that we have achieved reasonable prediction.

# Production OCR

Knowing how one might perform OCR with SVM is important, but you probably won't ever need to go down that road. Why? There are already great tools that will do the work for you (it should not come as a surprise, but deep neural networks are being used for intelligent character recognition). Probably the easiest one to work with is `Tesseract`. Tesseract has been supported by Google for several years now and continues to make great leaps. A combination of `ImageMagick`, `Tesseract`, and `pdftools` will handle just about any image-based data extraction needs that you might have.

If you are interested in the implementations and what else they can do, check out the pages for <a href="https://cran.r-project.org/web/packages/magick/vignettes/intro.html">magick</a> and <a href="https://cran.r-project.org/web/packages/tesseract/vignettes/intro.html">tesseract</a>.

```{r}
library(magick)

# library(pdftools)

library(tesseract)

loveCraftLetter = ocr("C://Users/sberry5/Documents/teaching/courses/unstructured/data/lovecraftLetter.jpg")

cat(loveCraftLetter)

letterConfidence = ocr_data("C://Users/sberry5/Documents/teaching/courses/unstructured/data/lovecraftLetter.jpg")

letterConfidence
```

That is pretty good on its own. This document also gives us some insight into the difficulties between OCR and ICR (intelligent character recognition). Machines do a great job with machine-generated text, but have a tougher time (out of the gate) with handwritten text.

If this image is a data, and all data needs cleaned, then let's clean up our data for hopefully improved results.

```{r}
loveCraftLetter = image_read("C://Users/sberry5/Documents/teaching/courses/unstructured/data/lovecraftLetter.jpg")

cleanedLetter = loveCraftLetter %>% 
  image_resize("2000x") %>%
  image_convert(type = "Grayscale") %>% 
  image_trim(fuzz = 50) %>%   # This should sharpen the images (i.e., letters)
  image_write(format = "png", density = "600x600", quality = 100)

cleanedRead = ocr(cleanedLetter)

cleanedConfidence = ocr_data(cleanedLetter)
  
```

Certainly better on some characters/words.

Next time, we are going to talk tabulizer...hopefully!