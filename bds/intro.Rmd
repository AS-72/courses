---
title: | 
      | Introduction To 
      | Behavioral Data Science
author: "Behavioral Data Science"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = "")

library(dplyr)
```


# Week 1

## Person-centric Data

Data from the people, about the people! Person-centric data covers a broad range of potential forms and sources. It might be survey data with attitudinal variables, purchase history, number of visits to the doctor's office, number of alcoholic drinks had during the last seven days, internet browsing behavior, or even Tweets. If we start to consider all of the data that we see, it becomes clear that a great deal of data is person-centric.

Not all data fits into this notion of person-centricity. We often find financial data (think end of day trading) that really does not fit into our notion of person-centric data. Even though this type of stock-flavored financial data does not really fit, the amount of money a person spends certainly does. Furthermore, much public data exists for municipal entities, such as county assessors. It might seem like a properties record is not person-centric, but we could build data that tracks a person's property buying/selling -- we would certainly look at such data and consider it to be behavioral in nature.

## Where Do We Go?

What do we do with person-centric, behavioral data? In general, we want to predict or explain behavior in some way! To do that, we need to create some hypotheses. We must, however, be very careful in crafting our hypotheses. While we can do some fancy analyses that start to lead us down a more causal path, we can never fully generalize what makes people do the things that they do.

This will be a theme that is revisted during our time together. Just so that you can start to fully get your head around hypotheses, let's take the first try at a little game.

I am noticing that visitors to my site spend less time on one page compared to other pages. Here is what that data might look like:

```{r, echo = FALSE}
visitorData = data.frame(visitorID = c(1, 1, 1, 2, 2, 3, 3, 3, 3), 
                         pageID = c("a", "b", "c", "a", "b", "a", 
                                    "b", "c", "d"), 
                         secondsOnPage = rnorm(9, mean = 15, sd = 4))
visitorData
```

I have a visitor identification number, a page identifier, and the number of seconds each user spent on a given page. Do I have data that would allow me to test if there is a difference in the amount of time that people spend on a page? I certainly do! With the data that you see, could I determine exactly why there might be differences in time on page? I would say rather unlikely with the provided data. We always need to make sure that we are not speaking beyond our data!

This was just a demo version of the game -- you will unlock more difficult levels as we progress. 

### Analyzing Behavioral Data

Think back to your linear models course. Do you remember examining adjusted $R^2$? It is one of the more popular measures of how well a particular model explains the data (adjusted $R^2$ is noted as how much variance in the dependent variable is explained by the predictor variables in the equation). We traditionally are pushed towards looking for very high values. Students come from a variety of statistical traditions have been taught a great many "thresholds" for acceptable $R^2$ values -- anywhere from .4 to .7 can be mentioned all in the span of a few seconds. If, however, we are trying to explain what someone does (i.e., a particular behavior), what are the chances that we will obtain such adjusted $R^2$ values? Probably not very high, right? People are messy and often unpredictable, so achieving huge $R^2$ values is unlikely. 

Does a small $R^2$ mean that your model is garbage&#8253; Of course not! A small $R^2$ does absolutely nothing to take away from the relationships between your predictor variables and your outcome. A low $R^2$ might mean that you have more error in your prediction, but there are still better ways of figuring that out than just looking at one value and giving up.

This is not to suggest that we should accept an $R^2$ of .000001 as the most predictive model in the world (note -- it probably is not); however, we should not be terribly dejected to see a model with 4 or 5 predictors with an $R^2$ around .2. That means that we have taken one of nature's sloppiest and most unpredictable creatures, and explained 20% of the variance of a behavior.

With that aside on $R^2$ out of the way, we can think more generally about analyzing behavioral data (that is why we are here). The Behavioral Sciences have a rich tradition of interesting analyses: from experimental design to causal models and all points in between. When dealing with behavioral data, we are frequently looking at some type of latent variables; these are constructs we think exist, but have no way to phyically touch them. We are going to be dealing in the latent world for the majority of our time together, so start thinking about latent variables now!

## Data Wrangling

Person-centric data comes in many different flavors. 

There is the classic cross-sectional wide format (tends towards a vanilla taste):

```{r, echo = FALSE}
classicWide = data.frame(id = 1:5, 
                         satisfaction = sample(1:7, 5, replace = TRUE), 
                         leftTip = sample(0:1, 5, replace = TRUE))
```

```{r, echo = FALSE}
classicWide
```


We also have repeated measures:

```{r, echo = FALSE}
repeatedMeasures = data.frame(id = rep(1:3, each = 3),
                              observation = rep(1:3, 3),
                              satisfaction = sample(1:5, 9, replace = TRUE),
                              leftTip = sample(0:1, 9, replace = TRUE)) %>% 
  mutate(rating = satisfaction + sample(1:2, 9, replace = TRUE))

repeatedMeasures
```


And. key-value pairs:

```{r, echo = FALSE}
repeatedMeasures %>% 
  tidyr::gather(key = variable, value = value)
```


And then from there, we can start to do combinations:

```{r, echo = FALSE}
repeatedMeasures %>% 
    tidyr::gather(key = variable, value = value, -id)
```


All of these have their place. Many analyses require traditional wide data. Others, like panel models, require long data (e.g., our repeated measures data).


```{r}
library(plm)

panelModel = plm(rating ~ satisfaction, index = c("id", "observation"), 
                 data = repeatedMeasures)

summary(panelModel)
```


Sometimes, we need to reshape our data for the sake of visualization (such visualizations are especially handy for survey questions). 

```{r, echo = FALSE}
library(ggplot2)
datTest = data.frame(id = as.factor(1:3),
           satisfaction1 = sample(1:7, 3, replace = TRUE), 
           satisfaction2 = sample(1:7, 3, replace = TRUE), 
           satisfaction3 = sample(1:7, 3, replace = TRUE))
datTest
```

If we want to show several people's survey responses, we need to do some reshaping:

```{r, echo = FALSE}
datTest %>% 
  tidyr::gather(key = variable, value = value, -id) %>% 
  ggplot(., aes(id, value, color = variable)) +
  geom_point(alpha = .5, size = 3) +
  theme_minimal()
```


See if you can reproduce the data and visualization!

No matter the need, don't be afraid to shape your data in a way that conforms to *your* needs. Always remember that you are in control of your data -- your data is not in control of you! With various packages from the tidyverse and base, you are have the power to make your data be whatever you need it to be.

*Link to dataWranglingPrimer.html*

## Ethical Considerations

When dealing with person-centric data, we need to always be thinking about ethics. Are we treating the data in a secure manner and honoring people's privacy? Are we being honest to people about how we are going to handle their data? These are questions that require your care and attention. 

This becomes even more important when sharing data. Look at the following data and think about whether or not it could be shared as is:

```{r}
data.frame(age = sample(18:35, 5, replace = TRUE), 
           gender = sample(c("male", "female"), 5, replace = TRUE), 
           department = sample(c("cs", "hr", "it"), 5, replace = TRUE), 
           score = sample(50:100, 5)) 
```

There are not any personal identifiers here, so we are good to put it on Github or Google Drive and share away...right? Let's pick this apart a little bit. Any of the demographic-inclined variables, in isolation, are not a cause for any concern; when we have all of them together, though, we might be able to identify individuals. Triangulation is a real concern with any type of data, but we need to be diligent in good security and privacy practices when we are dealing with person-centric data. This gets into an area known as de-identification -- the removal of not only concrete identifiers (e.g., names, SSNs), but also anything that can be pieced together to identify a person.

It might seem far fetched that anyone would ever go through the trouble of identifying your data, but you should think conspiratorially when it comes to your data -- imagine the absolute worst thing that could happen if someone took it and identified it. Could it cause personal problems, job lose, or reveal something embarrassing/illegal? Remember, the 4Chan collective found a flag in rural Tennessee using contrail patterns, star alignment, and a car horn -- in 37 hours. Don't forget that they also contributed to the identification and subsequent airstrike of an ISIS training facility. Just imagine what could be done with your interesting data.   


# Week 2


## Data Types And Structures

We see many different types of data when working with behavioral data, well beyond what we typically think about with our different levels of measurement (nominal, ordinal, interval, and ratio). 

### Attitudinal Data

Survey data is where we typically find attitudinal data and it tends to present some interesting issues. How are the items measured -- are they traditional Likert response options (*strongly disagree* to *strongly agree*) or are they some type of feelings thermometers (typically some crazy range that could be anywhere between 0 to 100 or -100 to 100). Perhaps it is a Likert-type (*Not at all* to *Very much*). How many response options are there -- 3, 5, 7, or more? 

When dealing with such attitudinal data, we might see data that takes any of the following forms:

```{r}
library(magrittr)
data.frame(agreementNumeric = 1:5, 
           agreementOrdered = ordered(1:5, labels = c("Strongly disagree", 
                                                      "Disagree", "Neither disagree nor agree", 
                                                      "Agree", "Strongly agree")), 
           agreementCharacter = c("Strongly disagree", 
                                  "Disagree", "Neither disagree nor agree", 
                                  "Agree", "Strongly agree"), 
           pseudoLikert = c("Not at all", "A little", "Some", "A lot", "Very much")) %T>%
  glimpse() %>% 
  summary()
```

This is where data familiarization and exploration becomes important -- always take note of variable types. If you are receiving this data from another source, you never know what you might be getting.

With the data as it is in its current form, think about what you might like to do with it. Would you like to plot or create a correlation matrix? Can you make that happen? Data processing becomes very important when working through any survey-based data.

What functions would you use to convert everything to numeric?

### Censored Data
We might run into data that is *censored*. While it might sound like something exciting at first, censored variables are simply those that we do not know about the values before or after data collection started/ended. You may run into variables that have been *discretized* -- a continuous variable, such as age, broken down into discreet categories. When we get that age variable, we might see categories like "<25", "25-35", "36-45", "46-55", and "55+". When people have an age of "<25", we have left censored data -- we don't know how far to the "left" the value actually is, we just know that it is somewhere under 25. For our observations with "55+", we have right censored data -- we don't know how far to the right the value actually is. 

```{r, echo = FALSE}
data.frame(ageCategory = c("<25", "25-35", "36-45", "46-55", "55+"), 
           censored = c("Left censored", "Uncensored", "Uncensored", 
                        "Uncensored", "Right censored"))
```

While we won't be diving into them, tobit models are one such way for dealing with censored dependent variables.

The following is similar to an example from the AER package. The max number of reported affairs is 12, but that was at the time of reporting -- the philandeering partners could have engaged in more affairs after data was collected. To that end, we need to account for right censoring.

```{r, echo = TRUE}
library(AER)

data("Affairs")

fm.tobit = tobit(affairs ~ age + yearsmarried + religiousness,
                   right = 12, data = Affairs)

summary(fm.tobit)
```

#### *Special Note On Discretization*

If you find yourself on the planning end of some broader data collection efforts, absolutely resist the temptation (both internal or external) to discretize data. Some people will say, "But response rates...blah...blah...blah", or, "We have to make it easy.", or, "Think of the children." Consider the following data:

```{r, echo = FALSE}
data.frame(age = c("<25", "25-35", "36-45", 
                   "36-45", "46-55", "55+"))
```

You have 6 respondents -- what is the mean age of those respondents? I have no idea and neither do you! If you allow data to be collected this way, you are immediately imposing limits on what you might do with that data in the future. Someone will likely say, "Just take the middle point of the range and call that the response."  

```{r, echo = FALSE}
data.frame(age = c(25, 30, 40, 40, 50, 55)) %T>% 
  print(.) %>% 
  summarize(mean(age))
```

Great.~ We have an average now. What if the actual ages were as follows:

```{r, echo = FALSE}
data.frame(age = c(22, 30, 36, 45, 51, 72)) %T>% 
  print(.) %>% 
  summarize(mean(age))
```

What is your mean age now? Is it still 40? You decide if the difference in the answer is important or not. Maybe you decide it is not that different and are comfortable doing this. Let me pose an additional question: is a 25 year old the same as a 35 year old? Just think about that for your ownself: is 18 year old you the same as 24 year old you? 

And here is another common issue: someone will want to discretize an income variable and use it as an outcome variable in a model. You have the power to make that happen (think back to our friend ordered logistic regression from generalized linear models). To the person who was expecting a standard linear regression, they are going to be really confused when you show them more than 1 intercept! 

Remember, it is okay to make things easy on people, but give them some credit. Most people know how old they are -- if they won't tell you their exact age, they probably won't be inclined to tell you the range either. 

### Hierarchical Data

Also known has multilevel or nested data, *hierarchical* data is best defined by a classical example -- we could have students, nested within classrooms, nested within schools, nested within districts, and so on.

Here is what some nested data might look like:

```{r, echo = FALSE}
data.frame(id = 1:15,
           subgroup = rep(1:5, each = 3), 
           group = rep(1:3, each = 5))
```

We have an id variable, which is giving us an individual identifier. Each person is in 1 of 5 subgroups and each subgroup is in 1 of 3 groups. 

Depending on your needs, this structure can be utilized in your analyses (we are going to be getting into it within the next few weeks).

### Repeated Measures

Repeated measures can be thought of in the same way as longitudinal data -- we are measuring the same thing for a person for an extended period of time. If you want, you can even think of it as nested data; the time-based observations are nested within an individual.

Here is how that data will typically look:

```{r}
data.frame(id = rep(1:3, each = 3), 
           observation = rep(1:3, each = 3), 
           responseTimeSeconds = sample(1:5, 9, replace = TRUE))
```

This data shows us 3 different people, each with 3 different observations. 
### Text

Welcome to the now! With people generating volume after volume of text, we have many questions that we can explore.

We can also have a bit of exploratory fun!

```{r, echo = FALSE}
library(wordcloud2)

presidentialTweets = c("The highly anticipated meeting between Kim Jong Un and myself will take place in Singapore on June 12th. We will both try to make it a very special moment for World Peace!", 
                       "Senator Cryin’ Chuck Schumer fought hard against the Bad Iran Deal, even going at it with President Obama, & then Voted AGAINST it! Now he says I should not have terminated the deal - but he doesn’t really believe that! Same with Comey. Thought he was terrible until I fired him!", 
                       "The Failing New York Times criticized Secretary of State Pompeo for being AWOL (missing), when in fact he was flying to North Korea. Fake News, so bad!", 
                       "The Fake News is working overtime. Just reported that, despite the tremendous success we are having with the economy & all things else, 91% of the Network News about me is negative (Fake). Why do we work so hard in working with the media when it is corrupt? Take away credentials?", 
                       "The Iran Deal is defective at its core. If we do nothing, we know what will happen. In just a short time, the world’s leading state sponsor of terror will be on the cusp of acquiring the world’s most dangerous weapons")

presidentialTweets %>% 
  tokenizers::tokenize_words(., strip_numeric = TRUE, 
                             stopwords = tm::stopwords("SMART")) %>%
  unlist() %>% 
  tm::stemDocument(.) %>% 
  table(.) %>% 
  as.data.frame(.) %>% 
  wordcloud2(., shape = "pentagon")
```

You can likely imagine the source.

## Sources Of Data

### Surveys

### Client-side Paradata/Metadata

### Records

### Social Media

## More Data Wrangling

*Link to dataWranglingPrimer.html*

## Ethical Considerations


# Week 3

## Data Exploration

Although we have identified our hypotheses and gotten our data into shape, that does not mean that we should just go right into 


## The Hypothesis-Data Consistency Link

> “A foolish consistency is the hobgoblin of little minds, adored by little statesmen and philosophers and divines. With consistency a great soul has simply nothing to do. He may as well concern himself with his shadow on the wall. Speak what you think now in hard words, and to-morrow speak what to-morrow thinks in hard words again, though it contradict every thing you said to-day. — 'Ah, so you shall be sure to be misunderstood.' — Is it so bad, then, to be misunderstood? Pythagoras was misunderstood, and Socrates, and Jesus, and Luther, and Copernicus, and Galileo, and Newton, and every pure and wise spirit that ever took flesh. To be great is to be misunderstood.” 

Emerson's (Ralph Waldo, not Keith) beautiful words are great if we are trying to expand our minds and engage in learning in general. One place that we cannot use this, however, is in connecting our data and hypotheses. If we have hypotheses about data, we had better have the data to test those hypotheses. While this may seem intuitive, behavioral data can often present unforeseen challenges. For example, you might be given some data full of attitudinal measures and someone has some ideas about relationships they want to test. If said person is not fully in the know about how to construct and test hypotheses, he/she might come to you wanting to test hypotheses that do not make sense given the data (maybe they want to "say" something about a scale that is not really measured by the scale).  




## Ethical Considerations

## More Data Issues