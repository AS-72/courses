---
title: "Missing Data"
author: "Behavioral Data Science"
date: "March 6, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Missing Data

Data generated by people has missing values -- this is an unfortunate truth. While shying away from the truth might someone's idea of a good time, missing data provides us with some interesting issues to tackle.

## Why Is Missing Data Important

The vast majority of statistical techniques are not robust to missingness. Take our standard linear model (lm):

```{r}
library(dplyr)
```


```{r}
library(magrittr)

testData = read.csv("missingSurvey.csv")

missingMod = testData %>% 
  lm(average_montly_hours ~ EMP_Engagement_5, data = .) %>% 
  summary()
```

Do you see any discrepancies? If we look at the number of rows within our data, we see a value of 14999. If, however, we take a look at our degrees of freedom from our model output, we see that a considerable amount of rows were dropped. A linear regression cannot use missing information, so the whole row gets dropped if any missingness exists. If an observation or dozen gets dropped out of a few hundred rows, we might not have too much to worry about. What about if more than half of the observations get dropped? It's probably not a good thing.


## Types Of Missingness

When we talk about missing data, it is easy to assume that it is just missing: nothing more and nothing less. What if we knew why those were missing. Would that change your thoughts on missingness? What if you knew that certain people did not responsd to certain questions (for example, people who do not identify with any particular religion may leave a question about religious strength blank). Just thinking about such an example, would group that kind of missingness with someone who just skipped a question purely through omission? You would likely say that they are different and you would be correct. Generally, we can think of three different types of missing values: missing completely at random, missing at random, and missing not at random.  

Data missing completely at random (MCAR), is exactly how it sounds -- the missing data is not related to any study variables and it is not related to any unknown process or parameter about the person generating the data. We can assume that MCAR data is not biased.

Data missing at random (MAR) is a bit different and little trickier. MAR data, despite the name, assumes that data is not really missing at random, but is instead fully explained by some other observed variable not related to the missing data. 

Missing not at random (MNAR) just extends MAR to assume that the missing data is caused by the missing data.

### Determining Missingness Types

Determining which type of missingness is present within your data can be tricky. In the most ideal world, we would have the data to know whether it is MCAR or something else. I think you can see the circular nature that we are getting ourselves in!

There are, however, some methods that will let us test our missingness. The MissMech package will perform some tests that can help.

```{r}
library(MissMech); library(dplyr)

# testData = read.csv("missingSurvey.csv")

mcarTest = TestMCARNormality(testData, del.lesscases = 200)

mcarTest
```

In our output, we get a glimpse at what patterns exists. We can see that there are 59 complete cases and 22 cases with mass missing. If we look at the Hawkins test, we would have to reject multivariate normality and MCAR. Our rejection of MCAR is only under the assumption of multivariate normality, which we already rejected. In looking at the non-parametric test, we can see that we likely cannot reject MCAR. 

The language here is important -- notice that there was very little in the way of absolutes. 

The TestMCARNormality function will only take numeric variables, so be sure to keep that in mind when using it.

If we can establish MCAR, then we can proceed with some imputation without fear of introducing a terrible amount of bias.

## Imputation Methods

Many types of mean imputation exist: mean imputation, median imputation, among others. The central tendancy-based imputation methods are classical holdovers. In essence, they replace a missing value with the mean/median of the column. When statistics were done on punchcards, this was probalby about the best that could be done.

## Multiple Imputation

### mice

Multiple imputation takes those simple imputation techniques much further. If we are using multivariate imputations by chained equations (mice), then we are going through a lengthy process to estimate the missing values and using several imputed datasets for our models. Data imputed with mice will use predictions on every variable around the missing data to predict the value of the missing data.

We are only interested in imputing our variable with missingness, so we will specify the "cart" method (classification and regression trees) for that variable and leave the other five blank.

```{r}
library(mice)

imputedData = mice(testData, m = 20, maxit = 20, 
                   method = c("", "", "", "", "", "sample"), 
                   pred = quickpred(testData, minpuc = .2), print = FALSE)

imputedData

plot(imputedData, layout = c(2, 1))
```

Will you look at that plot! These are trace lines. They track each imputation model over each iteraction. What do we take out of these? If they look like fuzzy caterpillars, the chained equation process was good. If there is any discernable pattern, then something odd might have happened -- these look just as crazy as they should! The mean for our imputed variable generally bounces around between 2.45 and 2.65. Given the observed mean, this seems pretty good.

Now, we have 20 imputed data sets that went through 20 iterations that we can perform separate analyses on.

```{r}
fit1 = with(data = imputedData, exp = lm(average_montly_hours ~ EMP_Engagement_5))
```

And we can then pool those results together:

```{r}
pool(fit1)
```

How different are these pooled coefficients compared to our previous coefficients? The pooled are certainly a bit stronger, but not terribly so. 

## Missing Or Sparse

On occasion you will see some data that looks like it has a lot of missingness. It might not truly be missing, it just might be sparse. Missing means that something was skipped (think about a survey question). In sparse data, the observations have a zero value. 